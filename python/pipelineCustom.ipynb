{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "from os import mkdir, makedirs, getcwd\n",
    "import scipy.stats as stats\n",
    "import nipype.interfaces.fsl as fsl\n",
    "from subprocess import call, Popen, check_output, CalledProcessError\n",
    "import nibabel as nib\n",
    "from shutil import copyfile, rmtree\n",
    "import scipy.io as sio\n",
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "from numpy.polynomial.legendre import Legendre\n",
    "import shlex\n",
    "from scipy import signal\n",
    "import operator\n",
    "import gzip\n",
    "from nilearn.signal import clean\n",
    "from nilearn.image import smooth_img\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import scipy.linalg as linalg\n",
    "import string\n",
    "import random\n",
    "import xml.etree.cElementTree as ET\n",
    "from time import localtime, strftime, sleep\n",
    "from scipy.fftpack import fft, dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regressors: to filter, no. time points x no. regressors\n",
    "def filter_regressors(regressors, filtering, nTRs, TR):\n",
    "    if len(filtering==0):\n",
    "        print 'Error! Missing or wrong filtering flavor. Regressors were not filtered.'\n",
    "    else:\n",
    "        if filtering[0] == 'Butter':\n",
    "            regressors = clean(regressors, detrend=False, standardize=False, \n",
    "                                  t_r=TR, high_pass=filtering[1], low_pass=filtering[2]).T\n",
    "        elif filtering[0] == 'Gaussian':\n",
    "            w = signal.gaussian(11,std=filtering[1])\n",
    "            regressors = signal.lfilter(w,1,regressors, axis=0)  \n",
    "    return regressors\n",
    "    \n",
    "def regress(niiImg, nTRs, TR, regressors, keepMean):\n",
    "    X  = np.concatenate((np.ones([nTRs,1]), regressors), axis=1)\n",
    "    N = niiImg.shape[0]\n",
    "    for i in range(N):\n",
    "        fit = np.linalg.lstsq(X, niiImg[i,:].T)[0]\n",
    "        fittedvalues = np.dot(X, fit)\n",
    "        resid = niiImg[i,:] - np.ravel(fittedvalues)\n",
    "        if keepMean:\n",
    "            niiImg[i,:] = X[:,0]*fit[0] + resid\n",
    "        else:\n",
    "            niiImg[i,:] = resid\n",
    "    return niiImg     \n",
    "\n",
    "def normalize(niiImg,flavor):\n",
    "    if flavor == 'zscore':\n",
    "        niiImg = stats.zscore(niiImg, axis=1, ddof=1)\n",
    "        return niiImg\n",
    "    elif flavor == 'pcSigCh':\n",
    "        niiImg = 100 * (niiImg - np.mean(niiImg,axis=1)[:,np.newaxis]) / np.mean(niiImg,axis=1)[:,np.newaxis]\n",
    "    else:\n",
    "        print 'Warning! Wrong normalization flavor. Nothing was done'\n",
    "    return niiImg    \n",
    "\n",
    "def legendre_poly(order, nTRs):\n",
    "    # ** a) create polynomial regressor **\n",
    "    x = np.arange(nTRs)\n",
    "    x = x - x.max()/2\n",
    "    num_pol = range(order+1)\n",
    "    y = np.ones((len(num_pol),len(x)))   \n",
    "    coeff = np.eye(order+1)\n",
    "    # Print out text file for each polynomial to be used as a regressor\n",
    "    for i in num_pol:\n",
    "        myleg = Legendre(coeff[i])\n",
    "        y[i,:] = myleg(x) \n",
    "        if i>0:\n",
    "            y[i,:] = y[i,:] - np.mean(y[i,:])\n",
    "            y[i,:] = y[i,:]/np.max(y[i,:])\n",
    "        np.savetxt(op.join(buildpath(subject,fmriRun),\n",
    "                           'poly_detrend_legendre' + str(i) + '.txt'), y[i,:] ,fmt='%.4f')\n",
    "    return y\n",
    "\n",
    "def load_img(fmriFile, maskAll):\n",
    "    if isCifti:\n",
    "        toUnzip = fmriFile.replace('_Atlas.dtseries.nii','.nii.gz')\n",
    "        cmd = 'wb_command -cifti-convert -to-text {} {}'.format(fmriFile,op.join(buildpath(subject,fmriRun),'.tsv'))\n",
    "        call(cmd,shell=True)\n",
    "    else:\n",
    "        toUnzip = fmriFile\n",
    "\n",
    "    with open(toUnzip, 'rb') as fFile:\n",
    "        decompressedFile = gzip.GzipFile(fileobj=fFile)\n",
    "        outFilePath = op.join(buildpath(subject, fmriRun), fmriRun+'.nii')\n",
    "        with open(outFilePath, 'wb') as outfile:\n",
    "            outfile.write(decompressedFile.read())\n",
    "\n",
    "    volFile = outFilePath\n",
    "\n",
    "    img = nib.load(volFile)\n",
    "    \n",
    "    myoffset = img.header.sizeof_hdr + 4 + img.header.get_data_offset()\n",
    "    data = np.memmap(volFile, dtype=img.header.get_data_dtype(), mode='c', order='F',\n",
    "                     offset=myoffset,shape=img.header.get_data_shape())\n",
    "\n",
    "    nRows, nCols, nSlices, nTRs = img.header.get_data_shape()\n",
    "    TR = img.header.structarr['pixdim'][4]\n",
    "    niiImg = data.reshape([nRows*nCols*nSlices, nTRs], order='F')\n",
    "    niiImg = niiImg[maskAll,:]\n",
    "    return niiImg, nRows, nCols, nSlices, nTRs, img.affine, TR\n",
    "\n",
    "def plot_hist(score,title,xlabel):\n",
    "    h,b = np.histogram(score, bins='auto')\n",
    "    plt.hist(score,bins=b)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Frequency')\n",
    "    return h\n",
    "\n",
    "def makeTissueMasks(subject,fmriRun,overwrite):\n",
    "    fmriFile = op.join(buildpath(subject,fmriRun), fmriRun+suffix+'.nii.gz')\n",
    "    WMmaskFileout = op.join(buildpath(subject,fmriRun), 'WMmask.nii')\n",
    "    CSFmaskFileout = op.join(buildpath(subject,fmriRun), 'CSFmask.nii')\n",
    "    GMmaskFileout = op.join(buildpath(subject,fmriRun), 'GMmask.nii')\n",
    "    \n",
    "    if not op.isfile(GMmaskFileout) or overwrite:\n",
    "        # load ribbon.nii.gz and wmparc.nii.gz\n",
    "        ribbonFilein = op.join(DATADIR, subject, 'MNINonLinear','ribbon.nii.gz')\n",
    "        wmparcFilein = op.join(DATADIR, subject, 'MNINonLinear', 'wmparc.nii.gz')\n",
    "        # make sure it is resampled to the same space as the functional run\n",
    "        ribbonFileout = op.join(buildpath(subject,fmriRun), 'ribbon.nii.gz')\n",
    "        wmparcFileout = op.join(buildpath(subject,fmriRun), 'wmparc.nii.gz')\n",
    "        # make identity matrix to feed to flirt for resampling\n",
    "        with open('eye.mat','w') as fid:\n",
    "            fid.write('1 0 0 0\\n0 1 0 0\\n0 0 1 0\\n0 0 0 1')\n",
    "        \n",
    "        flirt_ribbon = fsl.FLIRT(in_file=ribbonFilein, out_file=ribbonFileout,\\\n",
    "            reference=fmriFile, apply_xfm=True,\\\n",
    "            in_matrix_file='eye.mat', interp='nearestneighbour')\n",
    "        flirt_ribbon.run()\n",
    "\n",
    "        flirt_wmparc = fsl.FLIRT(in_file=wmparcFilein, out_file=wmparcFileout,\\\n",
    "            reference=fmriFile, apply_xfm=True,\\\n",
    "            in_matrix_file='eye.mat', interp='nearestneighbour')\n",
    "        flirt_wmparc.run()\n",
    "        \n",
    "        # load nii (ribbon & wmparc)\n",
    "        ribbon = nib.load(ribbonFileout).get_data()\n",
    "        wmparc = nib.load(wmparcFileout).get_data()\n",
    "        \n",
    "        # white & CSF matter mask\n",
    "        # indices are from FreeSurferColorLUT.txt\n",
    "        \n",
    "        # Left-Cerebral-White-Matter, Right-Cerebral-White-Matter\n",
    "        ribbonWMstructures = [2, 41]\n",
    "        # Left-Cerebral-Cortex, Right-Cerebral-Cortex\n",
    "        ribbonGMstrucures = [3, 42]\n",
    "        # Cerebellar-White-Matter-Left, Brain-Stem, Cerebellar-White-Matter-Right\n",
    "        wmparcWMstructures = [7, 16, 46]\n",
    "        # Left-Cerebellar-Cortex, Right-Cerebellar-Cortex, Thalamus-Left, Caudate-Left\n",
    "        # Putamen-Left, Pallidum-Left, Hippocampus-Left, Amygdala-Left, Accumbens-Left \n",
    "        # Diencephalon-Ventral-Left, Thalamus-Right, Caudate-Right, Putamen-Right\n",
    "        # Pallidum-Right, Hippocampus-Right, Amygdala-Right, Accumbens-Right\n",
    "        # Diencephalon-Ventral-Right\n",
    "        wmparcGMstructures = [8, 47, 10, 11, 12, 13, 17, 18, 26, 28, 49, 50, 51, 52, 53, 54, 58, 60]\n",
    "        # Fornix, CC-Posterior, CC-Mid-Posterior, CC-Central, CC-Mid-Anterior, CC-Anterior\n",
    "        wmparcCCstructures = [250, 251, 252, 253, 254, 255]\n",
    "        # Left-Lateral-Ventricle, Left-Inf-Lat-Vent, 3rd-Ventricle, 4th-Ventricle, CSF\n",
    "        # Left-Choroid-Plexus, Right-Lateral-Ventricle, Right-Inf-Lat-Vent, Right-Choroid-Plexus\n",
    "        wmparcCSFstructures = [4, 5, 14, 15, 24, 31, 43, 44, 63]\n",
    "        \n",
    "        # make masks\n",
    "        WMmask = np.double(np.logical_and(np.logical_and(np.logical_or(np.logical_or(np.in1d(ribbon, ribbonWMstructures),\n",
    "                                                                              np.in1d(wmparc, wmparcWMstructures)),\n",
    "                                                                np.in1d(wmparc, wmparcCCstructures)),\n",
    "                                                  np.logical_not(np.in1d(wmparc, wmparcCSFstructures))),\n",
    "                                   np.logical_not(np.in1d(wmparc, wmparcGMstructures))))\n",
    "        CSFmask = np.double(np.in1d(wmparc, wmparcCSFstructures))\n",
    "        GMmask = np.double(np.logical_or(np.in1d(ribbon,ribbonGMstrucures),np.in1d(wmparc,wmparcGMstructures)))\n",
    "        \n",
    "        # write masks\n",
    "        ref = nib.load(wmparcFileout)\n",
    "        WMmask = np.reshape(WMmask,ref.shape)\n",
    "        img = nib.Nifti1Image(WMmask, ref.affine)\n",
    "        nib.save(img, WMmaskFileout)\n",
    "        \n",
    "        CSFmask = np.reshape(CSFmask,ref.shape)\n",
    "        img = nib.Nifti1Image(CSFmask, ref.affine)\n",
    "        nib.save(img, CSFmaskFileout)\n",
    "        \n",
    "        GMmask = np.reshape(GMmask,ref.shape)\n",
    "        img = nib.Nifti1Image(GMmask, ref.affine)\n",
    "        nib.save(img, GMmaskFileout)\n",
    "        \n",
    "        # delete temporary files\n",
    "        cmd = 'rm eye.mat ribbon_flirt.mat wmparc_flirt.mat'\n",
    "        call(cmd,shell=True)\n",
    "        \n",
    "        \n",
    "    tmpnii = nib.load(WMmaskFileout)\n",
    "    myoffset = tmpnii.header.sizeof_hdr + 4 + tmpnii.header.get_data_offset()\n",
    "    data = np.memmap(WMmaskFileout, dtype=tmpnii.header.get_data_dtype(), mode='r', order='F',\n",
    "                     offset=myoffset,shape=tmpnii.header.get_data_shape())\n",
    "    nRows, nCols, nSlices = tmpnii.header.get_data_shape()\n",
    "    maskWM = np.reshape(data > 0,nRows*nCols*nSlices, order='F')\n",
    "    del data\n",
    "    tmpnii = nib.load(CSFmaskFileout)\n",
    "    myoffset = tmpnii.header.sizeof_hdr + 4 + tmpnii.header.get_data_offset()\n",
    "    data = np.memmap(CSFmaskFileout, dtype=tmpnii.header.get_data_dtype(), mode='r', order='F', \n",
    "                     offset=myoffset,shape=tmpnii.header.get_data_shape())\n",
    "    maskCSF = np.reshape(data > 0,nRows*nCols*nSlices, order='F')\n",
    "    del data\n",
    "    tmpnii = nib.load(GMmaskFileout)\n",
    "    myoffset = tmpnii.header.sizeof_hdr + 4 + tmpnii.header.get_data_offset()\n",
    "    data = np.memmap(GMmaskFileout, dtype=tmpnii.header.get_data_dtype(), mode='r', order='F', \n",
    "                     offset=myoffset,shape=tmpnii.header.get_data_shape())\n",
    "    maskGM = np.reshape(data > 0,nRows*nCols*nSlices, order='F')\n",
    "    del data\n",
    "    maskAll = np.logical_or(np.logical_or(maskWM, maskCSF), maskGM)\n",
    "    maskWM_ = maskWM[maskAll]\n",
    "    maskCSF_ = maskCSF[maskAll]\n",
    "    maskGM_ = maskGM[maskAll]\n",
    "    \n",
    "    return maskAll, maskWM_, maskCSF_, maskGM_\n",
    "\n",
    "\n",
    "def extract_noise_components(niiImg, num_components=5, extra_regressors=None):\n",
    "    \"\"\"Largely based on https://github.com/nipy/nipype/blob/master/examples/\n",
    "    rsfmri_vol_surface_preprocessing_nipy.py#L261\n",
    "    Derive components most reflective of physiological noise according to\n",
    "    aCompCor method (Behzadi 2007)\n",
    "    Parameters\n",
    "    ----------\n",
    "    niiImg: raw data\n",
    "    num_components: number of components to use for noise decomposition\n",
    "    extra_regressors: additional regressors to add\n",
    "    Returns\n",
    "    -------\n",
    "    components: n_time_points x regressors\n",
    "    \"\"\"\n",
    "    niiImgWMCSF = niiImg[np.logical_or(maskWM_,maskCSF_),:] \n",
    "    \n",
    "    niiImgWMCSF[np.isnan(np.sum(niiImgWMCSF, axis=1)), :] = 0\n",
    "    # remove mean and normalize by variance\n",
    "    # voxel_timecourses.shape == [nvoxels, time]\n",
    "    X = niiImgWMCSF.T\n",
    "    stdX = np.std(X, axis=0)\n",
    "    stdX[stdX == 0] = 1.\n",
    "    stdX[np.isnan(stdX)] = 1.\n",
    "    stdX[np.isinf(stdX)] = 1.\n",
    "    X = (X - np.mean(X, axis=0)) / stdX\n",
    "    u, _, _ = linalg.svd(X, full_matrices=False)\n",
    "    components = u[:, :num_components]\n",
    "    \n",
    "    if extra_regressors:\n",
    "        components = np.hstack((components, regressors))\n",
    "\n",
    "    return components\n",
    "\n",
    "def conf2XML(inFile, dataDir, operations, startTime, endTime, fname):\n",
    "    doc = ET.Element(\"pipeline\")\n",
    "    \n",
    "    nodeInput = ET.SubElement(doc, \"input\")\n",
    "    nodeInFile = ET.SubElement(nodeInput, \"inFile\")\n",
    "    nodeInFile.text = inFile\n",
    "    nodeDataDir = ET.SubElement(nodeInput, \"dataDir\")\n",
    "    nodeDataDir.text = dataDir\n",
    "    \n",
    "    nodeDate = ET.SubElement(doc, \"date\")\n",
    "    nodeDay = ET.SubElement(nodeDate, \"day\")\n",
    "    day = strftime(\"%Y-%m-%d\", localtime())\n",
    "    nodeDay.text = day\n",
    "    stime = strftime(\"%H:%M:%S\", startTime)\n",
    "    etime = strftime(\"%H:%M:%S\", endTime)\n",
    "    nodeStart = ET.SubElement(nodeDate, \"timeStart\")\n",
    "    nodeStart.text = stime\n",
    "    nodeEnd = ET.SubElement(nodeDate, \"timeEnd\")\n",
    "    nodeEnd.text = etime\n",
    "    \n",
    "    nodeSteps = ET.SubElement(doc, \"steps\")\n",
    "    for op in operations:\n",
    "        if op[1] == 0: continue\n",
    "        nodeOp = ET.SubElement(nodeSteps, \"operation\", name=op[0])\n",
    "        nodeOrder = ET.SubElement(nodeOp, \"order\")\n",
    "        nodeOrder.text = str(op[1])\n",
    "        nodeFlavor = ET.SubElement(nodeOp, \"flavor\")\n",
    "        nodeFlavor.text = str(op[2])\n",
    "    tree = ET.ElementTree(doc)\n",
    "    tree.write(fname)\n",
    "    \n",
    "def fnSubmitToCluster(strScript, strJobFolder, strJobUID, resources):\n",
    "    specifyqueue = ''\n",
    "    # clean up .o and .e\n",
    "    tmpfname = op.join(strJobFolder,strJobUID)\n",
    "    if op.isfile(tmpfname+'.e'): remove(tmpfname+'.e')       \n",
    "    if op.isfile(tmpfname+'.o'): remove(tmpfname+'.o')       \n",
    "   \n",
    "    strCommand = 'qsub {} -cwd -V {} -N {} -e \"{}\" -o \"{}\" \"{}\"'.format(specifyqueue,resources,strJobUID,\n",
    "                      op.join(strJobFolder,strJobUID+'.e'), op.join(strJobFolder,strJobUID+'.o'), strScript)\n",
    "    # write down the command to a file in the job folder\n",
    "    with open(op.join(strJobFolder,strJobUID+'.cmd'),'w+') as hFileID:\n",
    "        hFileID.write(strCommand+'\\n')\n",
    "    # execute the command\n",
    "    cmdOut = check_output(strCommand, shell=True)\n",
    "    return cmdOut.split()[2]    \n",
    "\n",
    "def _interpolate(a, b, fraction):\n",
    "    \"\"\"Returns the point at the given fraction between a and b, where\n",
    "    'fraction' must be between 0 and 1.\n",
    "    \"\"\"\n",
    "    return a + (b - a)*fraction;\n",
    "\n",
    "def scoreatpercentile(a, per, limit=(), interpolation_method='fraction'):\n",
    "    \"\"\"\n",
    "    This function is grabbed from scipy\n",
    "\n",
    "    \"\"\"\n",
    "    values = np.sort(a, axis=0)\n",
    "    if limit:\n",
    "        values = values[(limit[0] <= values) & (values <= limit[1])]\n",
    "\n",
    "    idx = per /100. * (values.shape[0] - 1)\n",
    "    if (idx % 1 == 0):\n",
    "        score = values[idx]\n",
    "    else:\n",
    "        if interpolation_method == 'fraction':\n",
    "            score = _interpolate(values[int(idx)], values[int(idx) + 1],\n",
    "                                 idx % 1)\n",
    "        elif interpolation_method == 'lower':\n",
    "            score = values[np.floor(idx)]\n",
    "        elif interpolation_method == 'higher':\n",
    "            score = values[np.ceil(idx)]\n",
    "        else:\n",
    "            raise ValueError(\"interpolation_method can only be 'fraction', \" \\\n",
    "                             \"'lower' or 'higher'\")\n",
    "\n",
    "    return score\n",
    "\n",
    "def dctmtx(N):\n",
    "    K=N\n",
    "    n = range(N)\n",
    "    C = np.zeros((len(n), K))\n",
    "    C[:,0] = np.ones((len(n)))/np.sqrt(N)\n",
    "    doublen = [2*x+1 for x in n]\n",
    "    for k in range(1,K):\n",
    "        C[:,k] = np.sqrt(2/N)*np.cos([np.pi*x*(k-1)/(2*N) for x in doublen])        \n",
    "    return C "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behavFile = 'unrestricted_luckydjuju_11_17_2015_0_47_11.csv'\n",
    "release = 'Q2'\n",
    "outScore = 'PMAT24_A_CR'\n",
    "pipelineName = 'Finn'\n",
    "parcellation = 'shenetal_neuroimage2013'\n",
    "overwrite = False\n",
    "thisRun = 'rfMRI_REST1'\n",
    "isDataClean = True\n",
    "doPlot = True\n",
    "queue = False\n",
    "normalize = 'zscore'\n",
    "isCifti = False\n",
    "keepMean = False\n",
    "class config(object):\n",
    "    filtering = []\n",
    "    doScrubbing = False\n",
    "\n",
    "# customize path to get access to single runs\n",
    "def buildpath(subject,fmriRun):\n",
    "    return op.join(DATADIR, subject,'MNINonLinear','Results',fmriRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these functions allow Paola & Julien to run code locally with their own path definitions\n",
    "def getDataDir(x):\n",
    "    return {\n",
    "        'esplmatlabw02.csmc.edu': '/home/duboisjx/vault/data/HCP/MRI',\n",
    "        'sculpin.caltech.edu': '/data/jdubois/data/HCP/MRI',\n",
    "    }.get(x, '/media/paola/HCP/')    # /media/paola/HCP is default if x not found\n",
    "def getParcelDir(x):\n",
    "    return {\n",
    "        'esplmatlabw02.csmc.edu': '/home/duboisjx/vault/data/parcellations/',\n",
    "        'sculpin.caltech.edu': '/data/jdubois/data/parcellations/',\n",
    "    }.get(x, '/data/pgaldi/parcellations/')    # /home/paola/parcellations/ is default if x not found\n",
    "import socket\n",
    "HOST=socket.gethostname()\n",
    "DATADIR=getDataDir(HOST)\n",
    "PARCELDIR=getParcelDir(HOST)\n",
    "\n",
    "#DATADIR = '/media/paola/HCP/'\n",
    "#PARCELDIR = '/home/paola/parcellations'\n",
    "\n",
    "if queue: priority=-100\n",
    "\n",
    "if thisRun == 'rfMRI_REST1':\n",
    "    outMat = 'rest_1_mat'\n",
    "elif thisRun == 'rfMRI_REST2':\n",
    "    outMat = 'rest_1_mat'\n",
    "else:\n",
    "    sys.exit(\"Invalid run code\")  \n",
    "    \n",
    "suffix = '_hp2000_clean' if isDataClean else ''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject = '734045'\n",
    "fmriRun = 'rfMRI_REST1_LR'\n",
    "fmriFile = op.join(buildpath(subject,fmriRun),'rfMRI_REST1_LR.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline workflow is defined by two dictionaries. \n",
    "\n",
    "The struct <b>Operations</b> encodes the order of generic pipeline steps, with 0 for skipping an operation, and otherwise a number indicating when the operation should be performed. Note that several operations may have the same position (e.g., motion regression and tissue regression may both have order = 3, which means they should be performed in the same regression). For each operation an array encodes the flavor of each step and parameters when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finn's pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Operations= [\n",
    "    ['VoxelNormalization',      1, ['zscore']],\n",
    "    ['Detrending',              2, ['legendre', 3, 'WMCSF']],\n",
    "    ['TissueRegression',        3, ['WMCSF']],\n",
    "    ['MotionRegression',        4, ['[R dR]']],\n",
    "    ['TemporalFiltering',       5, ['Gaussian', 1]],\n",
    "    ['Detrending',              6, ['legendre', 3,'GM']],\n",
    "    ['GlobalSignalRegression',  7, []],\n",
    "    ['Scrubbing',               0, ['fd', 0.2]],\n",
    "    ['SpatialSmoothing',        0, ['Gaussian', 6]],\n",
    "    ['ICAdenoising',            0, ['ICAFIX']],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every step is associated with a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MotionRegression(niiImg, flavor, masks, imgInfo):\n",
    "    # assumes that data is organized as in the HCP\n",
    "    motionFile = op.join(buildpath(subject,fmriRun), 'Movement_Regressors_dt.txt')\n",
    "    data = np.genfromtxt(motionFile)\n",
    "    if flavor[0] == 'R':\n",
    "        X = data[:,:6]\n",
    "    elif flavor[0] == 'R dR':\n",
    "        X = data\n",
    "    elif flavor[0] == 'R R^2':\n",
    "        data_squared = data ** 2\n",
    "        X = np.concatenate((data, data_squared), axis=1)\n",
    "    elif flavor[0] == 'R R^2 R-1 R-1^2':\n",
    "        data_roll = np.roll(data, 1, axis=0)\n",
    "        data_squared = data ** 2\n",
    "        data_roll[0] = 0\n",
    "        data_roll_squared = data_roll ** 2\n",
    "        X = np.concatenate((data, data_squared, data_roll, data_roll_squared), axis=1)\n",
    "    elif flavor[0] == 'R R^2 R-1 R-1^2 R-2 R-2^2':\n",
    "        data_roll = np.roll(data, 1, axis=0)\n",
    "        data_squared = data ** 2\n",
    "        data_roll[0] = 0\n",
    "        data_roll_squared = data_roll ** 2\n",
    "        data_roll2 = np.roll(data_roll, 1, axis=0)\n",
    "        data_roll2[0] = 0\n",
    "        data_roll2_squared = data_roll2 ** 2\n",
    "        X = np.concatenate((data, data_squared, data_roll, data_roll_squared, data_roll2, data_roll2_squared), axis=1)\n",
    "    else:\n",
    "        'Wrong flavor, using default regressors: R dR'\n",
    "        X = data\n",
    "        \n",
    "    # if filtering has already been performed, regressors need to be filtered too\n",
    "    if len(config.filtering)>0:\n",
    "        nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "        X = filter_regressors(X, config.filtering, nTRs, TR)  \n",
    "        \n",
    "    if config.doScrubbing:\n",
    "        toCensor = np.loadtxt(op.join(buildpath(subject,fmriRun), 'Censored_TimePoints.txt'), dtype=np.dtype(np.int32))\n",
    "        toReg = np.zeros((nTRs, 1))\n",
    "        toReg[toCensor] = 1\n",
    "        X = np.concatenate((X, toReg), axis=1)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def Scrubbing(niiImg, flavor, masks, imgInfo):\n",
    "    thr = flavor[1]\n",
    "    if flavor[0] == 'DVARS':\n",
    "        # pcSigCh\n",
    "        niiImg = 100 * niiImg / np.mean(niiImg,axis=1)[:,np.newaxis] -100\n",
    "        dt = np.diff(niiImg, n=1, axis=1)\n",
    "        dt = np.concatenate((np.zeros((dt.shape[0],1)), dt), axis=1)\n",
    "        score = np.sqrt(np.mean(dt**2,0))        \n",
    "    elif flavor[0] == 'FD':\n",
    "        motionFile = op.join(buildpath(subject,fmriRun), 'Movement_Regressors_dt.txt')\n",
    "        dmotpars = np.abs(np.genfromtxt(motionFile)[:,6:]) #derivatives\n",
    "        headradius=50 #50mm as in Powers et al.\n",
    "        disp=dmotpars.copy()\n",
    "        disp[:,3:]=np.pi*headradius*2*(disp[:,3:]/360)\n",
    "        score=np.sum(disp,1)\n",
    "    else:\n",
    "        print 'Wrong scrubbing flavor. Nothing was done'\n",
    "        return niiImg\n",
    "    censored = np.where(score>thr)\n",
    "    np.savetxt(op.join(buildpath(subject,fmriRun), 'Censored_TimePoints.txt'), delimiter='\\n', fmt='%d')\n",
    "    config.doScrubbing = True\n",
    "    return niiImg\n",
    "\n",
    "def TissueRegression(niiImg, flavor, masks, imgInfo):\n",
    "    maskAll, maskWM_, maskCSF_, maskGM_ = masks\n",
    "    nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "    \n",
    "    if isCifti:\n",
    "        niiImgGM = niiImg\n",
    "    else:\n",
    "        niiImgGM = niiImg[maskGM_,:]\n",
    "        \n",
    "    if flavor[0] == 'CompCor':\n",
    "        X = extract_noise_components(niiImg, num_components=flavor[1])\n",
    "        niiImgGM = regress(niiImgGM, nTRs, TR, X, keepMean)\n",
    "    elif flavor[0] == 'WMCSF':\n",
    "        meanWM = np.mean(np.float64(niiImg[maskWM_,:]),axis=0)\n",
    "        meanWM = meanWM - np.mean(meanWM)\n",
    "        meanWM = meanWM/max(meanWM)\n",
    "        meanCSF = np.mean(np.float64(niiImg[maskCSF_,:]),axis=0)\n",
    "        meanCSF = meanCSF - np.mean(meanCSF)\n",
    "        meanCSF = meanCSF/max(meanCSF)\n",
    "        X  = np.concatenate((meanWM[:,np.newaxis], meanCSF[:,np.newaxis]), axis=1)\n",
    "        niiImgGM = regress(niiImgGM, nTRs, TR, X, keepMean)\n",
    "    elif flavor[0] == 'WMCSF+dt':\n",
    "        meanWM = np.mean(np.float64(niiImg[maskWM_,:]),axis=0)\n",
    "        meanWM = meanWM - np.mean(meanWM)\n",
    "        meanWM = meanWM/max(meanWM)\n",
    "        meanCSF = np.mean(np.float64(niiImg[maskCSF_,:]),axis=0)\n",
    "        meanCSF = meanCSF - np.mean(meanCSF)\n",
    "        meanCSF = meanCSF/max(meanCSF)\n",
    "        dtWM=np.zeros(meanWM.shape)\n",
    "        dtWM[1:] = np.diff(meanWM, n=1)\n",
    "        dtCSF=np.zeros(meanCSF.shape)\n",
    "        dtCSF[1:] = np.diff(meanCSF, n=1)\n",
    "        X  = np.concatenate((meanWM[:,np.newaxis], meanCSF[:,np.newaxis], \n",
    "                             dtWM[:,np.newaxis], dtCSF[:,np.newaxis]), axis=1)\n",
    "        niiImgGM = regress(niiImgGM, nTRs, TR, X, keepMean)\n",
    "    else:\n",
    "        print 'Warning! Wrong tissue regression flavor. Nothing was done'\n",
    "    if not isCifti:\n",
    "        niiImg[maskGM_,:] = niiImgGM\n",
    "    else:\n",
    "        niiImg = niiImgGM\n",
    "    return niiImg\n",
    "\n",
    "def Detrending(niiImg, flavor, masks, imgInfo):\n",
    "    maskAll, maskWM_, maskCSF_, maskGM_ = masks\n",
    "    nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "    \n",
    "    if flavor[2] == 'WMCSF':\n",
    "        niiImgWMCSF = niiImg[np.logical_or(maskWM_,maskCSF_),:]\n",
    "        if flavor[0] == 'legendre':\n",
    "            y = legendre_poly(flavor[1],nTRs)                \n",
    "            niiImgWMCSF = regress(niiImgWMCSF, nTRs, TR, y[1:4,:].T, keepMean)\n",
    "        elif flavor[0] == 'poly':       \n",
    "            x = np.arange(nTRs)\n",
    "            nPoly = flavor[0] + 1\n",
    "            y = np.ones((nPoly,len(x)))\n",
    "            for i in range(nPoly):\n",
    "                y[i,:] = (x - (np.max(x)/2)) **(i+1)\n",
    "                y[i,:] = y[i,:] - np.mean(y[i,:])\n",
    "                y[i,:] = y[i,:]/np.max(y[i,:]) \n",
    "            niiImgWMCSF = regress(niiImgWMCSF, nTRs, TR, y[1:4,:].T, keepMean)\n",
    "        else:\n",
    "            print 'Warning! Wrong detrend flavor. Nothing was done'\n",
    "        niiImg[np.logical_or(maskWM_,maskCSF_),:] = niiImgWMCSF    \n",
    "    elif flavor[2] == 'GM':\n",
    "        if isCifti:\n",
    "            niiImgGM = niiImg\n",
    "        else:\n",
    "            niiImgGM = niiImg[maskGM_,:]\n",
    "\n",
    "        if flavor[0] == 'legendre':\n",
    "            y = legendre_poly(flavor[1], nTRs)\n",
    "            niiImgGM = regress(niiImgGM, nTRs, TR, y[1:4,:].T, keepMean)\n",
    "        elif flavor[0] == 'poly':       \n",
    "            x = np.arange(nTRs)\n",
    "            nPoly = flavor[0] + 1\n",
    "            y = np.ones((nPoly,len(x)))\n",
    "            for i in range(nPoly):\n",
    "                y[i,:] = (x - (np.max(x)/2)) **(i+1)\n",
    "                y[i,:] = y[i,:] - np.mean(y[i,:])\n",
    "                y[i,:] = y[i,:]/np.max(y[i,:])\n",
    "            niiImgGM = regress(niiImgGM, nTRs, TR, y[1:4,:].T, keepMean)\n",
    "        else:\n",
    "            print 'Warning! Wrong detrend flavor. Nothing was done'\n",
    "\n",
    "        if not isCifti:\n",
    "            niiImg[maskGM_,:] = niiImgGM\n",
    "        else:\n",
    "            niiImg = niiImgGM\n",
    "    else:\n",
    "        print 'Warning! Wrong detrend mask. Nothing was done' \n",
    "    return niiImg     \n",
    "\n",
    "   \n",
    "\n",
    "def SpatialSmoothing(niiImg, flavor, masks, imgInfo):\n",
    "    maskAll, maskWM_, maskCSF_, maskGM_ = masks\n",
    "    nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "    \n",
    "    niiimg = np.zeros((nRows*nCols*nSlices, nTRs))\n",
    "    niiimg[maskAll,:] = niiImg\n",
    "    niiimg = np.reshape(niiimg, (nRows, nCols, nSlices, nTRs), order='F')\n",
    "    newimg = nib.Nifti1Image(niiimg, affine)\n",
    "    if flavor[0] == 'Gaussian':\n",
    "        newimg = smooth_img(newimg, flavor[1])\n",
    "        niiimg = np.reshape(newimg.get_data(), (nRows*nCols*nSlices, nTRs), order='F')\n",
    "        niiImg = niiimg[maskAll,:]\n",
    "    elif flavor[0] == 'GaussianGM':\n",
    "        GMmaskFile = op.join(buildpath(subject,fmriRun),'GMmask.nii')\n",
    "        NiftiMasker(mask_img=GMmaskFile, sessions=None, smoothing_fwhm=flavor[1])\n",
    "        niiImg[maskGM_,:] = masker.fit_transform(newimg).T\n",
    "    else:\n",
    "        print 'Warning! Wrong smoothing flavor. Nothing was done'\n",
    "    return niiImg  \n",
    "\n",
    "def TemporalFiltering(niiImg, flavor, masks, imgInfo):\n",
    "    maskAll, maskWM_, maskCSF_, maskGM_ = masks\n",
    "    nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "    \n",
    "    if flavor[0] == 'Butter':\n",
    "        niiImg = clean(niiImg.T, detrend=False, standardize=False, \n",
    "                              t_r=TR, high_pass=flavor[1], low_pass=flavor[2]).T\n",
    "    elif flavor[0] == 'Gaussian':\n",
    "        w = signal.gaussian(11,std=flavor[1])\n",
    "        niiImg = signal.lfilter(w,1,niiImg)\n",
    "    elif flavor[0] == 'DCT':\n",
    "        K = dctmtx(nTRs)\n",
    "        HPC = 1/flavor[1]\n",
    "        LPC = 1/flavor[2]\n",
    "        nHP = np.fix(2*(nTRs*TR)/HPC + 1)\n",
    "        nLP = np.fix(2*(nTRs*TR)/LPC + 1)\n",
    "        K = K[:,np.concatenate((range(1,nHP),range(int(nLP)-1,nTRs)))]\n",
    "        return K\n",
    "    else:\n",
    "        print 'Warning! Wrong temporal filtering flavor. Nothing was done'    \n",
    "        return niiImg\n",
    "    config.filtering = flavor\n",
    "    return niiImg    \n",
    "    \n",
    "def ICAdenoising(niiImg, flavor, masks, imgInfo):\n",
    "    maskAll, maskWM_, maskCSF_, maskGM_ = masks\n",
    "    nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "    print 'ICAdenoising : '+flavor\n",
    "    print 'Warning! Method not implemented yet, nothing was done'\n",
    "    return niiImg\n",
    "\n",
    "def GlobalSignalRegression(niiImg, flavor, masks, imgInfo):\n",
    "    meanAll = np.mean(niiImg,axis=0)\n",
    "    meanAll = meanAll - np.mean(meanAll)\n",
    "    meanAll = meanAll/max(meanAll)\n",
    "    return meanAll[:,np.newaxis]\n",
    "\n",
    "def VoxelNormalization(niiImg, flavor, masks, imgInfo):\n",
    "    if flavor[0] == 'zscore':\n",
    "        niiImg = stats.zscore(niiImg, axis=1, ddof=1)\n",
    "        return niiImg\n",
    "    elif flavor[0] == 'pcSigCh':\n",
    "        niiImg = 100 * (niiImg - np.mean(niiImg,axis=1)[:,np.newaxis]) / np.mean(niiImg,axis=1)[:,np.newaxis]\n",
    "    else:\n",
    "        print 'Warning! Wrong normalization flavor. Nothing was done'\n",
    "    return niiImg  \n",
    "\n",
    "\n",
    "Hooks={\n",
    "    'MotionRegression'       : MotionRegression,\n",
    "    'Scrubbing'              : Scrubbing,\n",
    "    'TissueRegression'       : TissueRegression,\n",
    "    'Detrending'             : Detrending,\n",
    "    'SpatialSmoothing'       : SpatialSmoothing,\n",
    "    'TemporalFiltering'      : TemporalFiltering,  \n",
    "    'ICAdenoising'           : ICAdenoising,\n",
    "    'GlobalSignalRegression' : GlobalSignalRegression,  \n",
    "    'VoxelNormalization'     : VoxelNormalization,\n",
    "}\n",
    "\n",
    "sortedOperations = sorted(Operations, key=operator.itemgetter(1))\n",
    "steps = {}\n",
    "Flavors = {}\n",
    "cstep = 0\n",
    "for opr in sortedOperations:\n",
    "    if opr[1]==0:\n",
    "        continue\n",
    "    else:\n",
    "        if opr[1]!=cstep:\n",
    "            cstep=cstep+1\n",
    "            steps[cstep] = [opr[0]]\n",
    "            Flavors[cstep] = [opr[2]]\n",
    "        else:\n",
    "            steps[cstep].append(opr[0])\n",
    "            Flavors[cstep].append(opr[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps are executed sequentially. \n",
    "\n",
    "In case of regression, when multiple regression steps have the same order, all the regressors are combined and a single regression is executed (other operations are executed in order).\n",
    "\n",
    "Tissue regression has a custom handling, since regression is constrained to GM voxels.\n",
    "\n",
    "If filtering based on Discrete Cosine Transform (DCT) is involved, regression is used for band pass filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 VoxelNormalization ['zscore']\n",
      "False\n",
      "Step 2 Detrending ['legendre', 3, 'WMCSF']\n",
      "False\n",
      "Step 3 TissueRegression ['WMCSF']\n",
      "True\n",
      "Step 4 MotionRegression ['[R dR]']\n",
      "True\n",
      "Step 5 TemporalFiltering ['Gaussian', 1]\n",
      "True\n",
      "Step 6 Detrending ['legendre', 3, 'GM']\n",
      "False\n",
      "Step 7 GlobalSignalRegression []\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nsteps = len(steps)\n",
    "for i in range(1,nsteps+1):\n",
    "    step = steps[i]\n",
    "    print 'Step '+str(i)+' '+str(step[0])+' '+ str(Flavors[i][0])\n",
    "    \n",
    "    print str('Regression' in step[0] or ('TemporalFiltering' in step[0] and 'Gaussian' in Flavors[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runPipeline(subject, fmriRun, fmriFile):\n",
    "    \n",
    "    timeStart = localtime()\n",
    "    \n",
    "    print 'Step 0'\n",
    "    print 'Building WM, CSF and GM masks...'\n",
    "    masks = makeTissueMasks(subject,fmriRun,False)\n",
    "    maskAll, maskWM_, maskCSF_, maskGM_ = masks\n",
    "\n",
    "    print 'Loading data in memory...'\n",
    "    imgInfo = load_img(fmriFile, maskAll)\n",
    "    niiImg, nRows, nCols, nSlices, nTRs, affine, TR = imgInfo\n",
    "    nsteps = len(steps)\n",
    "    for i in range(1,nsteps+1):\n",
    "        step = steps[i]\n",
    "        print 'Step '+str(i)+' '+str(step[0])\n",
    "        \n",
    "        if len(step) == 1:\n",
    "            # Atomic operations\n",
    "            if 'Regression' in step[0] or ('TemporalFiltering' in step[0] and 'DCT' in Flavors[i][0]):\n",
    "                if step[0]=='TissueRegression': #regression constrained to GM\n",
    "                    niiImg = Hooks[step[0]](niiImg, Flavors[i][0], masks, imgInfo[1:])\n",
    "                else:\n",
    "                    r0 = Hooks[step[0]](niiImg, Flavors[i][0], masks, imgInfo[1:])\n",
    "                    niiImg = regress(niiImg, nTRs, TR, r0, keepMean)\n",
    "            else:\n",
    "                niiImg = Hooks[step[0]](niiImg, Flavors[i][0], masks, imgInfo[1:])\n",
    "        else:\n",
    "            # When multiple regression steps have the same order, all the regressors are combined\n",
    "            # and a single regression is performed (other operations are executed in order)\n",
    "            r = np.empty((nTRs, 0))\n",
    "            for j in range(len(step)):\n",
    "                opr = step[j]\n",
    "                if 'Regression' in opr or ('TemporalFiltering' in opr and 'DCT' in Flavors[i][j]):\n",
    "                    if opr=='TissueRegression': #regression constrained to GM\n",
    "                        niiImg = Hooks[opr](niiImg, Flavors[i][j], masks, imgInfo[1:])\n",
    "                    else:    \n",
    "                        r0 = Hooks[opr](niiImg, Flavors[i][j], masks, imgInfo[1:])\n",
    "                        r = np.append(r, r0, axis=1)\n",
    "                else:\n",
    "                    niiImg = Hooks[opr](niiImg, Flavors[i][j], masks, imgInfo[1:])\n",
    "            if r.shape[1] > 0:\n",
    "                niiImg = regress(niiImg, nTRs, TR, r, keepMean)    \n",
    "        niiImg[np.isnan(niiImg)] = 0\n",
    "\n",
    "    print 'Done! Copy the resulting file...'\n",
    "    rstring = ''.join(random.SystemRandom().choice(string.ascii_lowercase +string.ascii_uppercase + string.digits) for _ in range(8))\n",
    "    outFile = fmriRun+'_'+rstring\n",
    "    if isCifti:\n",
    "        # write to text file\n",
    "        np.savetxt(op.join(buildpath(subject,fmriRun),outfile+'.tsv'),niiImg, delimiter='\\t', fmt='%.6f')\n",
    "        # need to convert back to cifti\n",
    "        cmd = 'wb_command -cifti-convert -from-text {} {} {}'.format(op.join(buildpath(subject,fmriRun),'.tsv'),\n",
    "                                                                     fmriFile,\n",
    "                                                                     op.join(buildpath(subject,fmriRun),outFile+'.dtseries.nii'))\n",
    "        call(cmd,shell=True)\n",
    "        # delete temporary files\n",
    "        cmd = 'rm -r {}/*.tsv'.format(buildpath(subject,fmriRun))\n",
    "        call(cmd,shell=True)\n",
    "        del niiImg\n",
    "    else:\n",
    "        niiimg = np.zeros((nRows*nCols*nSlices, nTRs))\n",
    "        niiimg[maskAll,:] = niiImg\n",
    "        del niiImg\n",
    "        niiimg = np.reshape(niiimg, (nRows, nCols, nSlices, nTRs), order='F')\n",
    "        newimg = nib.Nifti1Image(niiimg, affine)\n",
    "        nib.save(newimg,op.join(buildpath(subject,fmriRun),outFile+'.nii.gz'))\n",
    "        del niiimg \n",
    "\n",
    "    timeEnd = localtime()  \n",
    "    \n",
    "    outXML = rstring+'.xml'\n",
    "    conf2XML(fmriFile, DATADIR, sortedOperations, timeStart, timeEnd, op.join(buildpath(subject,fmriRun),outXML))\n",
    "    \n",
    "    print 'Preprocessing complete. Starting FC computation...'\n",
    "    # After preprocessing, functional connectivity is computed\n",
    "    ResultsDir = op.join(DATADIR,'Results'v\n",
    "    if not op.isdir(ResultsDir): mkdir(ResultsDir)\n",
    "    ResultsDir = op.join(ResultsDir,pipelineName)\n",
    "    if not op.isdir(ResultsDir): mkdir(ResultsDir)\n",
    "    ResultsDir = op.join(ResultsDir,parcellation)\n",
    "    if not op.isdir(ResultsDir): mkdir(ResultsDir)\n",
    "    if parcellation=='shenetal_neuroimage2013':\n",
    "        uniqueParcels = range(268)\n",
    "        isCifti = 0\n",
    "        parcelVolume = 'fconn_atlas_150_2mm.nii'\n",
    "    elif parcellation=='Glasser_Aseg_Suit':\n",
    "        isCifti = 1\n",
    "        parcelVolume = 'Parcels.dlabel.nii'\n",
    "        uniqueParcels = range(405)\n",
    "    else:\n",
    "        print \"Invalid parcellation code\"\n",
    "        return\n",
    "    \n",
    "    for iParcel in uniqueParcels:\n",
    "        if not isCifti:\n",
    "            parcelMaskFile = op.join(PARCELDIR,parcellation,'parcel{:03d}.nii.gz'.format(iParcel+1))\n",
    "            if not op.isfile(parcelMaskFile):\n",
    "                print 'Making a binary volume mask for each parcel'\n",
    "                mymaths1 = fsl.maths.MathsCommand(in_file=op.join(PARCELDIR, parcellation,'fconn_atlas_150_2mm.nii'),\\\n",
    "                    out_file=parcelMaskFile, args='-thr {:.1f} -uthr {:.1f}'.format(iParcel+1-0.1, iParcel+1+0.1)) \n",
    "                mymaths1.run()\n",
    "    if not op.isfile(fmriFile):\n",
    "        print fmriFile, 'does not exist'\n",
    "        return\n",
    "    \n",
    "    tsDir = op.join(buildpath(subject,fmriRun),parcellation)\n",
    "    if not op.isdir(tsDir): mkdir(tsDir)\n",
    "    alltsFile = op.join(ResultsDir,subject+'_'+fmriRun+'.txt')\n",
    "    \n",
    "    if not (op.isfile(alltsFile)) or overwrite:            \n",
    "        # calculate signal in each of the nodes by averaging across all voxels/grayordinates in node\n",
    "        print 'Extracting mean data from',str(len(uniqueParcels)),'parcels for ',outFile\n",
    "       \n",
    "        for iParcel in uniqueParcels:\n",
    "            tsFile = op.join(tsDir,'parcel{:03d}.txt'.format(iParcel+1))\n",
    "            if not op.isfile(tsFile):\n",
    "                if not isCifti:\n",
    "                    parcelMaskFile = op.join(PARCELDIR,parcellation,'parcel{:03d}.nii.gz'.format(iParcel+1))\n",
    "                    \n",
    "                    # simply average the voxels within the mask\n",
    "                    meants1 = fsl.ImageMeants(in_file=op.join(buildpath(subject,fmriRun),outFile+'.nii.gz'), out_file=tsFile, mask=parcelMaskFile)\n",
    "                    meants1.run()\n",
    "                else:\n",
    "                    # extract data in the parcel\n",
    "                    parcelMaskFile = op.join(PARCELDIR,parcellation,'parcel{:03d}.dscalar.nii'.format(iParcel+1))\n",
    "                    cmd = 'wb_command -cifti-label-to-roi {} {} -key {}'.format(\n",
    "                        op.joinpath(PARCELDIR,parcellation,parcelVolume), parcelMaskFile,iParcel+1)\n",
    "                    call(cmd,shell=True)\n",
    "                    cmd = 'wb_command -cifti-roi-average {} {} -cifti-roi {}'.format(\n",
    "                        op.join(buildpath(subject,fmriRun),outFile+'.nii.gz'),tsFile, parcelMaskFile)\n",
    "                \n",
    "        # concatenate all ts\n",
    "        print 'Concatenating data'\n",
    "        cmd = 'paste '+op.join(tsDir,'parcel*.txt')+' > '+alltsFile\n",
    "        call(cmd, shell=True)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runPipeline(subject, fmriRun, fmriFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(behavFile)\n",
    "\n",
    "# select subjects according to release\n",
    "if release == 'Q2':\n",
    "    ind = (df['Release'] == 'Q2') | (df['Release'] == 'Q1')\n",
    "elif release == 'S500':\n",
    "    ind = (df['Release'] != 'Q2') & (df['Release'] != 'Q1')\n",
    "else:\n",
    "    sys.exit(\"Invalid release code\")\n",
    "    \n",
    "# select subjects that have completed all fMRI\n",
    "ind = ind & ((df['fMRI_WM_Compl']== True) & (df['fMRI_Mot_Compl']==True) \n",
    "             & (df['fMRI_Lang_Compl']==True) & (df['fMRI_Emo_Compl']==True)         \n",
    "             & (df['RS-fMRI_Count']==4))\n",
    "                \n",
    "df = df[ind]  \n",
    "\n",
    "# check if either of the two subjects recommended for exclusion by HCP are still present\n",
    "df = df[~df['Subject'].isin(['209733','528446'])]\n",
    "df.index = range(df.shape[0])\n",
    "print 'Selected', str(df.shape[0]), 'from the release',release\n",
    "print 'Number of males is:', df[df['Gender']=='M'].shape[0]\n",
    "tmpAgeRanges = sorted(df['Age'].unique())\n",
    "print 'Age range is', tmpAgeRanges[0].split('-')[0], '-', tmpAgeRanges[-1].split('-')[1]\n",
    "\n",
    "# list of all selected subjects\n",
    "subjects = df['Subject']\n",
    "# pull their IQ, Age, Gender\n",
    "age = df['Age']\n",
    "gender = df['Gender']\n",
    "score = df[outScore]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusion of high-motion subjects\n",
    "Further exclude subjects with >0.14 frame-to-frame head motion estimate averged across both rest runs (arbitrary threshold as in Finn et al 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResultsDir = op.join(DATADIR,'Results')\n",
    "if not op.isdir(ResultsDir): mkdir(ResultsDir)\n",
    "ResultsDir = op.join(ResultsDir, pipelineName)\n",
    "if not op.isdir(ResultsDir): mkdir(ResultsDir)\n",
    "ResultsDir = op.join(ResultsDir, parcellation)\n",
    "if not op.isdir(ResultsDir): mkdir(ResultsDir)\n",
    "\n",
    "PEdirs = ['LR', 'RL']\n",
    "RelRMSMean = np.zeros([len(subjects), 2])\n",
    "excludeSub = list()\n",
    "\n",
    "for iSub in range(len(subjects)):\n",
    "    subject = str(subjects[iSub])\n",
    "    RelRMSMeanFile = op.join(buildpath(subject, thisRun+'_zz'), 'Movement_RelativeRMS_mean.txt')\n",
    "    fLR = RelRMSMeanFile.replace('zz','LR');\n",
    "    fRL = RelRMSMeanFile.replace('zz','RL');\n",
    "    \n",
    "    if op.isfile(fLR) & op.isfile(fRL):\n",
    "        with open(fLR,'r') as tmp:\n",
    "            RelRMSMean[iSub,0] = float(tmp.read())\n",
    "        with open(fRL,'r') as tmp:\n",
    "            RelRMSMean[iSub,1] = float(tmp.read())\n",
    "        print '{} {:.3f} {:.3f}'.format(subjects[iSub], RelRMSMean[iSub,0], RelRMSMean[iSub,1])\n",
    "        if np.mean(RelRMSMean[iSub,:]) > 0.14:\n",
    "            print subjects[iSub], ': too much motion, exclude'\n",
    "            excludeSub.append(iSub)\n",
    "            continue\n",
    "    \n",
    "\n",
    "    for iPEdir in range(len(PEdirs)):\n",
    "        PEdir=PEdirs[iPEdir]\n",
    "        fmriRun = thisRun+'_'+PEdir\n",
    "        if parcellation=='shenetal_neuroimage2013':\n",
    "            fmriFile = op.join(buildpath(subject,fmriRun), fmriRun+suffix+'.nii.gz')\n",
    "            isCifti=0\n",
    "        elif parcellation=='Glasser_Aseg_Suit':\n",
    "            fmriFile = op.join(buildpath(subject,fmriRun), fmriRun+'_Atlas'+suffix+'.dtseries.nii')\n",
    "            isCifti=1\n",
    "        else:\n",
    "            print 'Wrong parcellation code'\n",
    "            return\n",
    "        if not op.isfile(fmriFile):\n",
    "            print str(subjects[iSub]), 'missing', fmriFile, ', exclude'\n",
    "            excludeSub.append(iSub)\n",
    "            continue\n",
    "        \n",
    "        if not (op.isfile(op.join(ResultsDir, str(subjects[iSub])+'_'+thisRun+'_'+PEdir+'.txt'))) or overwrite:\n",
    "            print 'load and preprocess'\n",
    "            if queue:\n",
    "                # make a script to load and preprocess that file, then save as .mat\n",
    "                jobDir = op.join(buildpath(str(subjects[iSub]),thisRun+'_'+PEdir),'jobs')\n",
    "                if not op.isdir(jobDir): mkdir(jobDir)\n",
    "                thispythonfn = '<< END\\nimport sys\\nsys.path.insert(0,\"{}\")\\n'.format(getcwd())\n",
    "                thispythonfn +='from runPipeline import *\\nrunPipeline(\"{}\",\"{}\",\"{}\")\\nEND'.format(subject,fmriRun,fmriFile)\n",
    "                thispythonfn += 'subject = \"{}\"\\n'.format(subject)\n",
    "                thispythonfn += 'fmriRun = \"{}\"\\n'.format(fmriRun)\n",
    "                thispythonfn += 'runPipeline(\"{}\",\"{}\",\"{}\")\\nEND'.format(subject,fmriRun,fmriFile)\n",
    "                        \n",
    "                jobName = 's{}_{}_{}_{}'.format(subjects[iSub],thisRun,PEdir, pipelineName)\n",
    "                # prepare a script\n",
    "                thisScript=op.join(jobDir,jobName+'.sh')\n",
    "                with open(thisScript,'w') as fidw:\n",
    "                    fidw.write('#!/bin/bash\\n')\n",
    "                    fidw.write('echo ${FSLSUBALREADYRUN}\\n')\n",
    "                    fidw.write('python {}'.format(thispythonfn))\n",
    "                cmd='chmod 774 '+thisScript\n",
    "                call(cmd,shell=True)\n",
    "                # call to fnSubmitToCluster\n",
    "                JobID = fnSubmitToCluster(thisScript,jobDir, jobName, '-p {} -l h_vmem=20G'.format(priority))\n",
    "                joblist.append(JobID)\n",
    "            else:\n",
    "                runPipeline(subject, fmriRun, fmriFile)\n",
    "        else:\n",
    "            print subject[iSub], ' : ', PEdir, 'results already computed; skipping'\n",
    "\n",
    "indkeep = np.setdiff1d(range(len(subjects)),excludeSub, assume_unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for all processes to complete, before resuming pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if queue:\n",
    "    if len(joblist) != 0:\n",
    "        while True:\n",
    "            nleft = len(joblist)\n",
    "            for i in range(nleft):\n",
    "                myCmd = \"qstat | grep ' {} '\".format(joblist[i])\n",
    "                isEmpty = False\n",
    "                try:\n",
    "                    cmdOut = check_output(myCmd, shell=True)\n",
    "                except CalledProcessError as e:\n",
    "                    isEmpty = True\n",
    "                finally:\n",
    "                    if isEmpty:\n",
    "                        nleft = nleft-1\n",
    "            if nleft == 0:\n",
    "                break\n",
    "            sleep(10)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(score[indkeep],np.mean(RelRMSMean[indkeep,:],axis=1),c='b')\n",
    "plt.scatter(score[excludeSub],np.mean(RelRMSMean[excludeSub,:],axis=1),c='r')\n",
    "# fit a curve to the data using a least squares 1st order polynomial fit\n",
    "z1 = np.polyfit(score[indkeep],np.mean(RelRMSMean[indkeep,:],axis=1),1)\n",
    "z2 = np.polyfit(score,np.mean(RelRMSMean,axis=1),1)\n",
    "p1 = np.poly1d(z1)\n",
    "p2 = np.poly1d(z2)                \n",
    "fit1 = p1(score[indkeep])\n",
    "fit2 = p2(score)\n",
    "# get the coordinates for the fit curve\n",
    "c1_x = [np.min(score[indkeep]),np.max(score[indkeep])]\n",
    "c1_y = p1(c1_x)\n",
    "c2_x = [np.min(score),np.max(score)]\n",
    "c2_y = p2(c2_x)\n",
    "# plot line of best fit\n",
    "plt.plot(c2_x,c2_y,'r-',label='before exclusion')\n",
    "plt.plot(c1_x,c1_y,'b-',label='after exclusion')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "rho1,p1 = stats.pearsonr(score[indkeep],np.mean(RelRMSMean[indkeep,:],axis=1))\n",
    "rho2,p2 = stats.pearsonr(score,np.mean(RelRMSMean,axis=1))                         \n",
    "print 'With all subjects: corr(IQ,motion) = {:.3f} (p = {:.3f})'.format(rho2,p2)\n",
    "print 'After discarding high movers: corr(IQ,motion) = {:.3f} (p = {:.3f})'.format(rho1,p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlate all pairs of node timecourses, resulting in 268x268 matrix of r-values.\n",
    "\n",
    "Apply Fisher transform to obtain 268x268 matrix of z-scores. The LR and RL runs are never concatenated. Rather, we run the above pipeline on each run separately and average the two resulting matrices of z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if parcellation=='shenetal_neuroimage2013':\n",
    "    nParcels = 268\n",
    "elif parcellation=='Glasser_Aseg_Suit':\n",
    "    nParcels = 405\n",
    "corrmats = np.zeros([nParcels,nParcels,len(indkeep)])\n",
    "scores = np.zeros([len(indkeep)])\n",
    "index = 0\n",
    "for iSub in range(len(subjects)):\n",
    "    if iSub not in excludeSub:\n",
    "        PEdir=PEdirs[iPEdir] \n",
    "        tsFile_LR=op.join(ResultsDir,str(subjects[iSub])+'_'+thisRun+'_LR.txt')\n",
    "        tsFile_RL=op.join(ResultsDir,str(subjects[iSub])+'_'+thisRun+'_RL.txt')\n",
    "        ts_LR = np.loadtxt(tsFile_LR)\n",
    "        ts_RL = np.loadtxt(tsFile_RL)\n",
    "        # Fisher z transform of correlation coefficients\n",
    "        corrMat_LR = np.arctanh(np.corrcoef(ts_LR,rowvar=0))\n",
    "        corrMat_RL = np.arctanh(np.corrcoef(ts_RL,rowvar=0))\n",
    "        np.fill_diagonal(corrMat_LR,1)\n",
    "        np.fill_diagonal(corrMat_RL,1)\n",
    "        corrmats[:,:,index] = (corrMat_LR + corrMat_RL)/2\n",
    "        scores[index] = score[iSub]\n",
    "        \n",
    "results = {}\n",
    "results[outMat] = corrmats\n",
    "results[outScore] = scores\n",
    "sio.savemat(op.join(ResultsDir,'{}_HCP_{}.mat'.format(thisRun,release)),results)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
